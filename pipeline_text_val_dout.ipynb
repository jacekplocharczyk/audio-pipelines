{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.7.5 (default, Oct 25 2019, 15:51:11) \n",
      "[GCC 7.3.0]\n",
      "__pyTorch VERSION: 1.2.0\n",
      "__CUDA VERSION\n",
      "/bin/sh: 1: nvcc: not found\n",
      "__CUDNN VERSION: 7301\n",
      "__Number CUDA Devices: 2\n",
      "__Devices\n",
      "Active CUDA Device: GPU 0\n",
      "Available devices  2\n",
      "Current cuda device  0\n",
      "3.7.5 (default, Oct 25 2019, 15:51:11) \n",
      "[GCC 7.3.0]\n",
      "12.1\n",
      "svmem(total=67477729280, available=39792410624, percent=41.0, used=26440957952, free=35440160768, active=22673412096, inactive=2971639808, buffers=82165760, cached=5514444800, shared=496238592, slab=5049528320)\n",
      "memory GB: 0.24885940551757812\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, ShuffleSplit, cross_val_score, train_test_split\n",
    "\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "# call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "\n",
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor\n",
    "\n",
    "import pandas\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "handler=logging.basicConfig(level=logging.INFO)\n",
    "lgr = logging.getLogger(__name__)\n",
    "%matplotlib inline\n",
    "\n",
    "# !pip install psutil\n",
    "import psutil\n",
    "import os\n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "\n",
    "cpuStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "# use_cuda = False\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "Tensor = FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/audio-pipelines/data\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyps = pd.read_csv(\"sets/full_set/hyps\", names=['audio_id'])\n",
    "# hyps[['audio_id','hyps']] = hyps[\"audio_id\"].str.split(\" \", 1, expand=True)\n",
    "\n",
    "# targets = pd.read_csv(\"sets/full_set/targets\", names=['audio_id'])\n",
    "# targets[['audio_id','target']] = targets[\"audio_id\"].str.split(\" \", 1, expand=True)\n",
    "\n",
    "# text = pd.read_csv(\"sets/full_set/text\", names=['audio_id'])\n",
    "# text[['audio_id','text']] = text[\"audio_id\"].str.split(\" \", 1, expand=True)\n",
    "\n",
    "# speakers = pd.read_csv(\"sets/full_set/utt2spk\", names=['audio_id'])\n",
    "# speakers[['audio_id','speaker']] = speakers[\"audio_id\"].str.split(\" \", 1, expand=True)\n",
    "\n",
    "# images = pd.read_csv(\"sets/full_set/wav.scp\", names=['audio_id'])\n",
    "# images[['audio_id','audio_path']] = images[\"audio_id\"].str.split(\" \", 1, expand=True)\n",
    "\n",
    "# dataset = pd.merge(hyps, text, how=\"left\")\n",
    "# dataset = pd.merge(dataset, speakers, how=\"left\")\n",
    "# dataset = pd.merge(dataset, images, how=\"left\")\n",
    "# dataset = pd.merge(dataset, targets, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['image_path'] = dataset['audio_path'].apply(lambda x : x[:-4] + \".png\")\n",
    "# def remove_absolute(string, prefix='/home/raznem/projects/audio-pipelines/data/'):\n",
    "#     if string.startswith(prefix):\n",
    "#         string = string[len(prefix):]\n",
    "#     return string\n",
    "    \n",
    "# dataset['image_path'] = dataset['image_path'].apply(remove_absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.to_csv('data/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from allennlp.commands.elmo import ElmoEmbedder\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "    \n",
    "toImg = transforms.ToPILImage()\n",
    "toTensor = transforms.ToTensor()\n",
    "    \n",
    "class WavImagesLoader(Dataset):\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.dataset = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        target = self.dataset['target'][key]\n",
    "        image_path = self.dataset['image_path'][key]\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert('RGB')\n",
    "        image = toTensor(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    @staticmethod        \n",
    "    def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))    \n",
    "\n",
    "#     @staticmethod    \n",
    "#     def flaotTensorToImage(img, mean=0, std=1):\n",
    "#         \"\"\"convert a tensor to an image\"\"\"\n",
    "#         img = np.transpose(img.numpy(), (1, 2, 0))\n",
    "#         img = (img*std+ mean)*255\n",
    "#         img = img.astype(np.uint8)    \n",
    "#         return img    \n",
    "    \n",
    "    \n",
    "class ElmoWavImagesLoader(WavImagesLoader):\n",
    "    def __init__(self, csv_path, text_vecs_path, transform=None):\n",
    "        super().__init__(csv_path, transform=None)\n",
    "        self.text_vecs_path = text_vecs_path\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        target = self.dataset['target'][key]\n",
    "        image_path = self.dataset['image_path'][key]\n",
    "        image = Image.open(image_path)\n",
    "        image = image.convert('RGB')\n",
    "        image = toTensor(image)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        text_vec = np.zeros((322, 1024))\n",
    "        tmp = np.load(self.text_vecs_path + self.dataset[\"audio_id\"][key] + \".npy\")\n",
    "        tmp = np.sum(tmp, axis=0)\n",
    "        text_len = tmp.shape[0]\n",
    "        text_vec[:tmp.shape[0],:tmp.shape[1]] = tmp\n",
    "        \n",
    "        return image, text_vec, text_len, target\n",
    "    \n",
    "    \n",
    "class ElmoWavVecLoader(ElmoWavImagesLoader):\n",
    "    def __init__(self, csv_path, text_vecs_path, transform=None):\n",
    "        super().__init__(csv_path, text_vecs_path, transform=None)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        target = self.dataset['target'][key]\n",
    "        image_vec = self.dataset['image_vec'][key]\n",
    "        text = self.dataset['hyps'][key]\n",
    "        text = text.split(' ')\n",
    "        \n",
    "        text_vec = np.zeros(322, 1024)\n",
    "        tmp = np.load(text_vecs_path + self.dataset[\"audio_id\"][key] + \".npy\")\n",
    "        text_len = tmp.shape[0]\n",
    "        text_vec[:tmp.shape[0],:tmp.shape[1]] = tmp\n",
    "\n",
    "        return image_vec, text_vec, text_len, target\n",
    "    \n",
    "    \n",
    "class ElmoLoader(WavImagesLoader):\n",
    "    def __init__(self, csv_path, text_vec_list, transform=None):\n",
    "        super().__init__(csv_path, transform=None)\n",
    "        self.text_vec_list = text_vec_list\n",
    "            \n",
    "    def __getitem__(self, key):\n",
    "        target = self.dataset['target'][key]\n",
    "        text_vec = np.zeros((322, 1024))\n",
    "        tmp = self.text_vec_list[key]\n",
    "        text_len = tmp.shape[0]\n",
    "        text_vec[:tmp.shape[0],:tmp.shape[1]] = tmp\n",
    "\n",
    "        return text_vec, text_len, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"text_vec_list.p\", \"rb\") as f:\n",
    "    text_vec_list = pkl.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv net to get vector from Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = torch.nn.Dropout(p=0.30)\n",
    "class ConvRes(nn.Module):\n",
    "    def __init__(self, insize, outsize):\n",
    "        super(ConvRes, self).__init__()\n",
    "        drate = .3\n",
    "        self.math = nn.Sequential(\n",
    "            nn.BatchNorm2d(insize),\n",
    "            # nn.Dropout(drate),\n",
    "            torch.nn.Conv2d(insize, outsize, kernel_size=2, padding=2),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.math(x)\n",
    "\n",
    "\n",
    "class ConvCNN(nn.Module):\n",
    "    def __init__(self, insize, outsize, kernel_size=7, padding=2, pool=2, avg=True):\n",
    "        super(ConvCNN, self).__init__()\n",
    "        self.avg = avg\n",
    "        self.math = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(insize, outsize, kernel_size=kernel_size, padding=padding),\n",
    "            torch.nn.BatchNorm2d(outsize),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.MaxPool2d(pool, pool),\n",
    "        )\n",
    "        self.avgpool = torch.nn.AvgPool2d(pool, pool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.math(x)\n",
    "        if self.avg is True:\n",
    "            x = self.avgpool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.cnn1 = ConvCNN(3, 32, kernel_size=7, pool=4, avg=False)\n",
    "        self.cnn2 = ConvCNN(32, 32, kernel_size=5, pool=2, avg=True)\n",
    "        self.cnn3 = ConvCNN(32, 32, kernel_size=5, pool=2, avg=True)\n",
    "\n",
    "        self.res1 = ConvRes(32, 64)\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            self.cnn1, dropout,\n",
    "            self.cnn2,\n",
    "            self.cnn3,\n",
    "            self.res1,\n",
    "        )\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(5184, output_dim),\n",
    "        )\n",
    "        self.sig = nn.Sigmoid()\n",
    "  \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "#         x = self.sig(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# if use_cuda:\n",
    "#     lgr.info (\"Using the GPU\")\n",
    "#     model = Net(output_dim).cuda() # On GPU\n",
    "# else:\n",
    "#     lgr.info (\"Using the CPU\")\n",
    "#     model = Net(output_dim) # On CPU\n",
    "\n",
    "# lgr.info('Model {}'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get maximum length of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_text_length = dataset_dropna['hyps'].apply(lambda x: len(x.split(' '))).max()\n",
    "# max_text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data = ElmoLoader('data/dataset_dropna.csv', text_vec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN to encode Elmo sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModel(Net):\n",
    "    def __init__(self, rnn_dim, layers_rnn=1, text_emb_dim=1024):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers_rnn = layers_rnn\n",
    "        self.text_emb_dim = text_emb_dim\n",
    "        self.rnn_dim = rnn_dim\n",
    "        self.text_lstm = nn.LSTM(text_emb_dim, self.rnn_dim, num_layers=self.layers_rnn, batch_first=True)\n",
    "        self.fc_last = nn.Linear(rnn_dim, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_len):        \n",
    "#         cnn_out = self.cnn_model(img)\n",
    "        seq_lengths = text_len\n",
    "        pack = torch.nn.utils.rnn.pack_padded_sequence(text, seq_lengths, batch_first=True)\n",
    "        _, (rnn_out, _) = self.text_lstm(pack)\n",
    "#         print(rnn_out.shape)\n",
    "        rnn_out = rnn_out.reshape(-1, self.rnn_dim)\n",
    "#         x = torch.cat([cnn_out, rnn_out], dim=1)\n",
    "#         print(rnn_out.shape)\n",
    "        y_pred = self.fc_last(rnn_out)\n",
    "        y_pred = torch.squeeze(y_pred)\n",
    "        y_pred = self.sig(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModelDout(Net):\n",
    "    def __init__(self, rnn_dim, layers_rnn=1, text_emb_dim=1024, dout_rate=0.3):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers_rnn = layers_rnn\n",
    "        self.text_emb_dim = text_emb_dim\n",
    "        self.rnn_dim = rnn_dim\n",
    "        self.text_lstm = nn.LSTM(text_emb_dim, self.rnn_dim, num_layers=self.layers_rnn, dropout=dout_rate, batch_first=True)\n",
    "        self.fc_last = nn.Linear(rnn_dim, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_len):        \n",
    "#         cnn_out = self.cnn_model(img)\n",
    "        seq_lengths = text_len\n",
    "        pack = torch.nn.utils.rnn.pack_padded_sequence(text, seq_lengths, batch_first=True)\n",
    "        _, (rnn_out, _) = self.text_lstm(pack)\n",
    "#         print(rnn_out.shape)\n",
    "        rnn_out = torch.mean(rnn_out, 0)\n",
    "        rnn_out = rnn_out.reshape(-1, self.rnn_dim)\n",
    "#         x = torch.cat([cnn_out, rnn_out], dim=1)\n",
    "#         print(rnn_out.shape)\n",
    "        y_pred = self.fc_last(rnn_out)\n",
    "        y_pred = torch.squeeze(y_pred)\n",
    "        y_pred = self.sig(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextModelDout_v2(Net):\n",
    "    def __init__(self, rnn_dim, layers_rnn=1, text_emb_dim=1024, dout_rate=0.3):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers_rnn = layers_rnn\n",
    "        self.text_emb_dim = text_emb_dim\n",
    "        self.rnn_dim = rnn_dim\n",
    "        self.text_lstm = nn.LSTM(text_emb_dim, self.rnn_dim, num_layers=self.layers_rnn, dropout=dout_rate, batch_first=True)\n",
    "        self.fc_last = nn.Linear(rnn_dim, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.dout = nn.modules.Dropout(dout_rate)\n",
    "        \n",
    "    def forward(self, text, text_len):        \n",
    "#         cnn_out = self.cnn_model(img)\n",
    "        seq_lengths = text_len\n",
    "        text = self.dout(text)\n",
    "        pack = torch.nn.utils.rnn.pack_padded_sequence(text, seq_lengths, batch_first=True)\n",
    "        _, (rnn_out, _) = self.text_lstm(pack)\n",
    "#         print(rnn_out.shape)\n",
    "        rnn_out = torch.mean(rnn_out, 0)\n",
    "        rnn_out = rnn_out.reshape(-1, self.rnn_dim)\n",
    "#         x = torch.cat([cnn_out, rnn_out], dim=1)\n",
    "#         print(rnn_out.shape)\n",
    "        y_pred = self.fc_last(rnn_out)\n",
    "        y_pred = torch.squeeze(y_pred)\n",
    "        y_pred = self.sig(y_pred)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_val = pd.read_csv('data/dataset_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_data = WavImagesLoader(csv_path)\n",
    "# dataloader = DataLoader(image_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rval_acc(result, target):\n",
    "    result = (result > 0.7).type(torch.int)\n",
    "    target = target.type(torch.int)\n",
    "    acc = target == result\n",
    "    acc = acc.type(torch.float32).sum()/len(acc)\n",
    "    return acc\n",
    "\n",
    "def validate(model, loader_val, dtype):\n",
    "    prediction_list = []\n",
    "    target_list = []\n",
    "    with torch.no_grad():\n",
    "        for i, (text, text_len, y) in enumerate(loader_val):\n",
    "            text, text_len = text.to(dtype=dtype), text_len.to(dtype=dtype)\n",
    "            text_len, perm_idx = text_len.sort(0, descending=True)\n",
    "            text = text[perm_idx]\n",
    "            y = y[perm_idx]\n",
    "            pred = model(text, text_len).to(\"cpu\")\n",
    "            prediction_list.append(pred)\n",
    "            target_list.append(y)\n",
    "    result = torch.squeeze(torch.cat(prediction_list))\n",
    "    target = torch.squeeze(torch.cat(target_list))\n",
    "    acc = rval_acc(result, target)\n",
    "    print(f'Acc {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def textspec_trainer(loader_train, loader_val, model, optimizer, exp_name='', val_every=None, \n",
    "                     save_every=None, print_every=None, epochs=1, use_gpu=True, \n",
    "                     dtype=torch.float32):\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        device = torch.device('cuda:1')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        \n",
    "    model.train()\n",
    "    model.to(device=device)\n",
    "    model.eval()\n",
    "    model.to(device='cpu')\n",
    "    validate(model, loader_val, dtype)\n",
    "    model.to(device=device)\n",
    "    model.train()\n",
    "    for e in range(epochs):\n",
    "        print('Epoch %d' %e)\n",
    "        acc = 0\n",
    "        files_no = 0\n",
    "        for t, (text, text_len, y) in enumerate(loader_train):\n",
    "#             img = img.to(device=device, dtype=dtype)\n",
    "            text = text.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "            text_len, perm_idx = text_len.sort(0, descending=True)\n",
    "            text = text[perm_idx]\n",
    "#             img = img[perm_idx]\n",
    "            y = y[perm_idx]\n",
    "            \n",
    "            y_pred = model(text, text_len)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            \n",
    "            acc += (torch.round(y_pred.cpu()) == y.cpu()).sum().type(torch.float32)\n",
    "            files_no += len(text)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if print_every is not None and t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f; epoch %d' % (t, loss.item(), e))\n",
    "                print(f'Acc {acc / files_no}')\n",
    "                \n",
    "        if val_every is not None and e % val_every == 0:\n",
    "            model.eval()\n",
    "            model.to(device='cpu')\n",
    "            validate(model, loader_val, dtype)\n",
    "            model.to(device=device)\n",
    "            model.train()\n",
    "        if save_every is not None and e % save_every == 0:\n",
    "            torch.save(model.state_dict(), f'models/{exp_name}_e%d_cnn_rnn.pt' % e)\n",
    "            gc.collect()\n",
    "    torch.save(model.state_dict(), f'models/{exp_name}_cnn_rnn.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"text_vec_list.p\", \"rb\") as f:\n",
    "    text_vec_list = pkl.load(f)\n",
    "\n",
    "with open(\"text_vec_list_val.p\", \"rb\") as f:\n",
    "    text_vec_list_val = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc 0.5184999704360962\n",
      "Epoch 0\n",
      "Iteration 0, loss = 0.6920; epoch 0\n",
      "Acc 0.5234375\n",
      "Iteration 100, loss = 0.6783; epoch 0\n",
      "Acc 0.5713180899620056\n",
      "Iteration 200, loss = 0.6579; epoch 0\n",
      "Acc 0.59017413854599\n",
      "Acc 0.5184999704360962\n",
      "Epoch 1\n",
      "Iteration 0, loss = 0.6794; epoch 1\n",
      "Acc 0.6171875\n",
      "Iteration 100, loss = 0.6922; epoch 1\n",
      "Acc 0.6110767126083374\n",
      "Iteration 200, loss = 0.7014; epoch 1\n",
      "Acc 0.609880268573761\n",
      "Epoch 2\n",
      "Iteration 0, loss = 0.6586; epoch 2\n",
      "Acc 0.609375\n",
      "Iteration 100, loss = 0.6482; epoch 2\n",
      "Acc 0.6098390817642212\n",
      "Iteration 200, loss = 0.6341; epoch 2\n",
      "Acc 0.6150886416435242\n",
      "Epoch 3\n",
      "Iteration 0, loss = 0.6573; epoch 3\n",
      "Acc 0.625\n",
      "Iteration 100, loss = 0.6249; epoch 3\n",
      "Acc 0.6293317079544067\n",
      "Iteration 200, loss = 0.6395; epoch 3\n",
      "Acc 0.6334344148635864\n",
      "Epoch 4\n",
      "Iteration 0, loss = 0.6294; epoch 4\n",
      "Acc 0.625\n",
      "Iteration 100, loss = 0.6341; epoch 4\n",
      "Acc 0.6486695408821106\n",
      "Iteration 200, loss = 0.6037; epoch 4\n",
      "Acc 0.6537624597549438\n",
      "Epoch 5\n",
      "Iteration 0, loss = 0.6205; epoch 5\n",
      "Acc 0.65625\n",
      "Iteration 100, loss = 0.6323; epoch 5\n",
      "Acc 0.6526144742965698\n",
      "Iteration 200, loss = 0.6327; epoch 5\n",
      "Acc 0.658076822757721\n",
      "Acc 0.5214999914169312\n",
      "Epoch 6\n",
      "Iteration 0, loss = 0.5957; epoch 6\n",
      "Acc 0.6640625\n",
      "Iteration 100, loss = 0.6414; epoch 6\n",
      "Acc 0.6636757254600525\n",
      "Iteration 200, loss = 0.5972; epoch 6\n",
      "Acc 0.6667444109916687\n",
      "Epoch 7\n",
      "Iteration 0, loss = 0.6241; epoch 7\n",
      "Acc 0.625\n",
      "Iteration 100, loss = 0.5706; epoch 7\n",
      "Acc 0.6610457897186279\n",
      "Iteration 200, loss = 0.6179; epoch 7\n",
      "Acc 0.6660447716712952\n",
      "Epoch 8\n",
      "Iteration 0, loss = 0.5920; epoch 8\n",
      "Acc 0.703125\n",
      "Iteration 100, loss = 0.6216; epoch 8\n",
      "Acc 0.6756651997566223\n",
      "Iteration 200, loss = 0.6332; epoch 8\n",
      "Acc 0.6720693111419678\n",
      "Epoch 9\n",
      "Iteration 0, loss = 0.6047; epoch 9\n",
      "Acc 0.65625\n",
      "Iteration 100, loss = 0.5873; epoch 9\n",
      "Acc 0.6752011179924011\n",
      "Iteration 200, loss = 0.6146; epoch 9\n",
      "Acc 0.6763059496879578\n",
      "Epoch 10\n",
      "Iteration 0, loss = 0.5775; epoch 10\n",
      "Acc 0.6640625\n",
      "Iteration 100, loss = 0.5484; epoch 10\n",
      "Acc 0.6810024976730347\n",
      "Iteration 200, loss = 0.5979; epoch 10\n",
      "Acc 0.6762670874595642\n",
      "Acc 0.5575000047683716\n",
      "Epoch 11\n",
      "Iteration 0, loss = 0.6046; epoch 11\n",
      "Acc 0.7265625\n",
      "Iteration 100, loss = 0.5919; epoch 11\n",
      "Acc 0.6830136179924011\n",
      "Iteration 200, loss = 0.5413; epoch 11\n",
      "Acc 0.6817863583564758\n",
      "Epoch 12\n",
      "Iteration 0, loss = 0.5609; epoch 12\n",
      "Acc 0.6953125\n",
      "Iteration 100, loss = 0.5351; epoch 12\n",
      "Acc 0.6814665794372559\n",
      "Iteration 200, loss = 0.5293; epoch 12\n",
      "Acc 0.6805037260055542\n",
      "Epoch 13\n",
      "Iteration 0, loss = 0.5857; epoch 13\n",
      "Acc 0.703125\n",
      "Iteration 100, loss = 0.6281; epoch 13\n",
      "Acc 0.6816213130950928\n",
      "Iteration 200, loss = 0.6265; epoch 13\n",
      "Acc 0.682097315788269\n",
      "Epoch 14\n",
      "Iteration 0, loss = 0.5714; epoch 14\n",
      "Acc 0.703125\n",
      "Iteration 100, loss = 0.5268; epoch 14\n",
      "Acc 0.6874226331710815\n",
      "Iteration 200, loss = 0.6131; epoch 14\n",
      "Acc 0.6845071315765381\n",
      "Epoch 15\n",
      "Iteration 0, loss = 0.5728; epoch 15\n",
      "Acc 0.6875\n",
      "Iteration 100, loss = 0.5396; epoch 15\n",
      "Acc 0.6874226331710815\n",
      "Iteration 200, loss = 0.5715; epoch 15\n",
      "Acc 0.6878498196601868\n",
      "Acc 0.5885000228881836\n",
      "Epoch 16\n",
      "Iteration 0, loss = 0.5492; epoch 16\n",
      "Acc 0.734375\n",
      "Iteration 100, loss = 0.5553; epoch 16\n",
      "Acc 0.6854888796806335\n",
      "Iteration 200, loss = 0.6637; epoch 16\n",
      "Acc 0.6865671873092651\n",
      "Epoch 17\n",
      "Iteration 0, loss = 0.5394; epoch 17\n",
      "Acc 0.75\n",
      "Iteration 100, loss = 0.5073; epoch 17\n",
      "Acc 0.6917543411254883\n",
      "Iteration 200, loss = 0.6072; epoch 17\n",
      "Acc 0.6913090944290161\n",
      "Epoch 18\n",
      "Iteration 0, loss = 0.5646; epoch 18\n",
      "Acc 0.703125\n",
      "Iteration 100, loss = 0.5852; epoch 18\n",
      "Acc 0.6860303282737732\n",
      "Iteration 200, loss = 0.5252; epoch 18\n",
      "Acc 0.6913868188858032\n",
      "Epoch 19\n",
      "Iteration 0, loss = 0.5532; epoch 19\n",
      "Acc 0.7265625\n",
      "Iteration 100, loss = 0.5880; epoch 19\n",
      "Acc 0.6914449334144592\n",
      "Iteration 200, loss = 0.6310; epoch 19\n",
      "Acc 0.6890158653259277\n",
      "Epoch 20\n",
      "Iteration 0, loss = 0.6281; epoch 20\n",
      "Acc 0.640625\n",
      "Iteration 100, loss = 0.5404; epoch 20\n",
      "Acc 0.6880414485931396\n",
      "Iteration 200, loss = 0.6617; epoch 20\n",
      "Acc 0.6902984976768494\n",
      "Acc 0.597000002861023\n",
      "Epoch 21\n",
      "Iteration 0, loss = 0.6424; epoch 21\n",
      "Acc 0.671875\n",
      "Iteration 100, loss = 0.5328; epoch 21\n",
      "Acc 0.6929919719696045\n",
      "Iteration 200, loss = 0.5872; epoch 21\n",
      "Acc 0.6939521431922913\n",
      "Epoch 22\n",
      "Iteration 0, loss = 0.5872; epoch 22\n",
      "Acc 0.6953125\n",
      "Iteration 100, loss = 0.6066; epoch 22\n",
      "Acc 0.6982518434524536\n",
      "Iteration 200, loss = 0.5931; epoch 22\n",
      "Acc 0.6957789063453674\n",
      "Epoch 23\n",
      "Iteration 0, loss = 0.5643; epoch 23\n",
      "Acc 0.7109375\n",
      "Iteration 100, loss = 0.5947; epoch 23\n",
      "Acc 0.6945390105247498\n",
      "Iteration 200, loss = 0.6758; epoch 23\n",
      "Acc 0.694807231426239\n",
      "Epoch 24\n",
      "Iteration 0, loss = 0.5405; epoch 24\n",
      "Acc 0.71875\n",
      "Iteration 100, loss = 0.5565; epoch 24\n",
      "Acc 0.6974009871482849\n",
      "Iteration 200, loss = 0.5745; epoch 24\n",
      "Acc 0.6999378204345703\n",
      "Epoch 25\n",
      "Iteration 0, loss = 0.5909; epoch 25\n",
      "Acc 0.671875\n",
      "Iteration 100, loss = 0.5579; epoch 25\n",
      "Acc 0.7008817791938782\n",
      "Iteration 200, loss = 0.5691; epoch 25\n",
      "Acc 0.699043869972229\n",
      "Acc 0.5924999713897705\n",
      "Epoch 26\n",
      "Iteration 0, loss = 0.5806; epoch 26\n",
      "Acc 0.703125\n",
      "Iteration 100, loss = 0.4927; epoch 26\n",
      "Acc 0.7011138796806335\n",
      "Iteration 200, loss = 0.5838; epoch 26\n",
      "Acc 0.7014925479888916\n",
      "Epoch 27\n",
      "Iteration 0, loss = 0.5500; epoch 27\n",
      "Acc 0.734375\n",
      "Iteration 100, loss = 0.5570; epoch 27\n",
      "Acc 0.6988706588745117\n",
      "Iteration 200, loss = 0.5989; epoch 27\n",
      "Acc 0.7015702724456787\n",
      "Epoch 28\n",
      "Iteration 0, loss = 0.4510; epoch 28\n",
      "Acc 0.796875\n",
      "Iteration 100, loss = 0.5714; epoch 28\n",
      "Acc 0.6991800665855408\n",
      "Iteration 200, loss = 0.6109; epoch 28\n",
      "Acc 0.7026974558830261\n",
      "Epoch 29\n",
      "Iteration 0, loss = 0.6319; epoch 29\n",
      "Acc 0.65625\n",
      "Iteration 100, loss = 0.5345; epoch 29\n",
      "Acc 0.7043626308441162\n",
      "Iteration 200, loss = 0.5595; epoch 29\n",
      "Acc 0.7039800882339478\n",
      "Epoch 30\n",
      "Iteration 0, loss = 0.5819; epoch 30\n",
      "Acc 0.6875\n",
      "Iteration 100, loss = 0.5419; epoch 30\n",
      "Acc 0.7072246074676514\n",
      "Iteration 200, loss = 0.5533; epoch 30\n",
      "Acc 0.7069340944290161\n",
      "Acc 0.5954999923706055\n",
      "Epoch 31\n",
      "Iteration 0, loss = 0.5691; epoch 31\n",
      "Acc 0.7109375\n",
      "Iteration 100, loss = 0.5673; epoch 31\n",
      "Acc 0.7052134871482849\n",
      "Iteration 200, loss = 0.5927; epoch 31\n",
      "Acc 0.7013370394706726\n",
      "Epoch 32\n",
      "Iteration 0, loss = 0.5877; epoch 32\n",
      "Acc 0.671875\n",
      "Iteration 100, loss = 0.5681; epoch 32\n",
      "Acc 0.7035117745399475\n",
      "Iteration 200, loss = 0.5989; epoch 32\n",
      "Acc 0.7018035054206848\n",
      "Epoch 33\n",
      "Iteration 0, loss = 0.5181; epoch 33\n",
      "Acc 0.734375\n",
      "Iteration 100, loss = 0.6195; epoch 33\n",
      "Acc 0.7090036869049072\n",
      "Iteration 200, loss = 0.5636; epoch 33\n",
      "Acc 0.705690324306488\n",
      "Epoch 34\n",
      "Iteration 0, loss = 0.5444; epoch 34\n",
      "Acc 0.6953125\n",
      "Iteration 100, loss = 0.5368; epoch 34\n",
      "Acc 0.7066057920455933\n",
      "Iteration 200, loss = 0.6113; epoch 34\n",
      "Acc 0.7087219953536987\n",
      "Epoch 35\n",
      "Iteration 0, loss = 0.5372; epoch 35\n",
      "Acc 0.734375\n",
      "Iteration 100, loss = 0.5385; epoch 35\n",
      "Acc 0.7104734182357788\n",
      "Iteration 200, loss = 0.4526; epoch 35\n",
      "Acc 0.7080612778663635\n",
      "Acc 0.5960000157356262\n",
      "Epoch 36\n",
      "Iteration 0, loss = 0.5580; epoch 36\n",
      "Acc 0.703125\n",
      "Iteration 100, loss = 0.5560; epoch 36\n",
      "Acc 0.7069925665855408\n",
      "Iteration 200, loss = 0.6088; epoch 36\n",
      "Acc 0.7069340944290161\n",
      "Epoch 37\n",
      "Iteration 0, loss = 0.5675; epoch 37\n",
      "Acc 0.734375\n",
      "Iteration 100, loss = 0.6010; epoch 37\n",
      "Acc 0.7095451951026917\n",
      "Iteration 200, loss = 0.5359; epoch 37\n",
      "Acc 0.7124145030975342\n",
      "Epoch 38\n",
      "Iteration 0, loss = 0.5907; epoch 38\n",
      "Acc 0.6640625\n",
      "Iteration 100, loss = 0.5913; epoch 38\n",
      "Acc 0.7066831588745117\n",
      "Iteration 200, loss = 0.6214; epoch 38\n",
      "Acc 0.7103933691978455\n",
      "Epoch 39\n",
      "Iteration 0, loss = 0.5615; epoch 39\n",
      "Acc 0.7734375\n",
      "Iteration 100, loss = 0.5590; epoch 39\n",
      "Acc 0.713335394859314\n",
      "Iteration 200, loss = 0.5159; epoch 39\n",
      "Acc 0.7108209133148193\n",
      "Epoch 40\n",
      "Iteration 0, loss = 0.5824; epoch 40\n",
      "Acc 0.671875\n",
      "Iteration 100, loss = 0.5426; epoch 40\n",
      "Acc 0.7141862511634827\n",
      "Iteration 200, loss = 0.4877; epoch 40\n",
      "Acc 0.7113650441169739\n",
      "Acc 0.6035000085830688\n",
      "Epoch 41\n",
      "Iteration 0, loss = 0.5628; epoch 41\n",
      "Acc 0.71875\n",
      "Iteration 100, loss = 0.5402; epoch 41\n",
      "Acc 0.7062190771102905\n",
      "Iteration 200, loss = 0.5653; epoch 41\n",
      "Acc 0.7105876803398132\n",
      "Epoch 42\n",
      "Iteration 0, loss = 0.5229; epoch 42\n",
      "Acc 0.7734375\n",
      "Iteration 100, loss = 0.5991; epoch 42\n",
      "Acc 0.7095451951026917\n",
      "Iteration 200, loss = 0.5736; epoch 42\n",
      "Acc 0.7119869589805603\n",
      "Epoch 43\n",
      "Iteration 0, loss = 0.4562; epoch 43\n",
      "Acc 0.796875\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-4\n",
    "USE_GPU = True\n",
    "TE_DTYPE = torch.float32\n",
    "CNN_DIM = 32\n",
    "RNN_DIM = 32\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "model = TextModelDout_v2(RNN_DIM, layers_rnn=2, dout_rate=0.5)\n",
    "image_data = ElmoLoader('data/dataset_dropna.csv', text_vec_list)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "loader_train = DataLoader(image_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=6)\n",
    "val_data = ElmoLoader('data/dataset_val.csv', text_vec_list_val)\n",
    "loader_val = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "textspec_trainer(loader_train, loader_val, model, optimizer, exp_name='text_dout_val', \n",
    "                 val_every=5, save_every=10, print_every=100, epochs=NUM_EPOCHS,\n",
    "      use_gpu=USE_GPU, dtype=TE_DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
